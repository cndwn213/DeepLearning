{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIvhXnvJN6XG"
      },
      "source": [
        "# 인코딩(encoding)과 디코딩(decoding)\n",
        "\n",
        "- 인코딩-디코딩 아키텍쳐는 통신, 암호, 전자 등 다양한 분야에 적용되는 일반적인 프레임워크\n",
        "\n",
        "- 인코더는 입력 샘플을 잠재 공간, 즉 인코더에 의해 정의된 숨겨진 구조화된 값 집합에 매핑하는 함수\n",
        "\n",
        "- 디코더는 이 잠재 공간의 요소를 사전 정의된 타겟 도메인으로 매핑하는 여함수\n",
        "\n",
        "- 예를 들어, 이미지와 오디오 압축 포맷\n",
        "\n",
        "  - JPEG 도구는 미디어 파일을 가벼운 이진파일로 압축하여 인코딩하고, 표시할 떄 픽셀 값을 복원하기 위해 디코딩\n",
        "\n",
        "  <img src=\"https://image.slidesharecdn.com/aes171113-180510014736/95/-48-638.jpg?cb=1525916931\">\n",
        "\n",
        "  <sub>[이미지 출처] https://www.slideshare.net/NaverEngineering/ss-96581209</sub>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwOvyt4WC84Z"
      },
      "source": [
        "# 오토인코더(Autoencoder, AE)\n",
        "\n",
        "- 입력을 저차원 잠재공간으로 인코딩한 후 디코딩하여 복원하는 네트워크  \n",
        "  즉, 이미지를 입력받아 인코더 모듈을 사용하여 잠재 벡터 공간으로 매핑하고,  \n",
        "  디코더 모듈을 사용하여 원본 이미지와 동일한 차원으로 복원하여 출력\n",
        "\n",
        "- 원본 입력을 재구성하는 방법으로 학습\n",
        "\n",
        "- 고전적인 방식은 구조화가 잘된 잠재 공간을 만들지 못하고,  \n",
        "  압축도 뛰어나지 않음\n",
        "\n",
        "  <img src=\"https://miro.medium.com/max/1200/1*nqzWupxC60iAH2dYrFT78Q.png\">\n",
        "\n",
        "  <sub>[이미지 출처] https://medium.com/@birla.deepak26/autoencoders-76bb49ae6a8f</sub>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBYkcHQYH8rA"
      },
      "source": [
        "## Fashon MNIST Dataset\n",
        "\n",
        "- 코드 참조 : https://www.tensorflow.org/tutorials/generative/autoencoder?hl=ko"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_lTtOABILk0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Reshape\n",
        "from tensorflow.keras.losses import MeanSquaredError"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LeqN5A51IHmo"
      },
      "source": [
        "### 데이터 로드"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CqQj97-0z9LL"
      },
      "outputs": [],
      "source": [
        "(X_train, _), (X_test, _) = fashion_mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wh04_ujz3n4J",
        "outputId": "bd0dd05c-3144-4310-c2ee-8cb421b4856c"
      },
      "outputs": [],
      "source": [
        "# 정규화\n",
        "X_train = X_train.astype(np.float32) / 255.\n",
        "X_test = X_test.astype('float32') / 255. \n",
        "X_train.shape, X_test.shape, np.min(X_train), np.max(X_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILnkElscIctE"
      },
      "source": [
        "### 모델 정의\n",
        "\n",
        "- 이미지를 64 차원 잠재 벡터로 압축하는 encoder 및 잠재 공간에서 원본 이미지를 재구성하는 decoder 라는 두 개의 Dense 레이어로 오토 encoder 정의\n",
        "\n",
        "- Keras Model Subclassing API를 사용"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DbEA2fM8H7Vu"
      },
      "outputs": [],
      "source": [
        "LATENT_DIM = 64\n",
        "\n",
        "class AutoEncoder(Model):\n",
        "    def __init__(self, latent_dim=LATENT_DIM):\n",
        "        super(AutoEncoder, self).__init__()\n",
        "        self.latent_dim = latent_dim\n",
        "        self.encoder = Sequential([Flatten(),\n",
        "                                   Dense(latent_dim, activation='relu')])\n",
        "        self.decoder = Sequential([Dense(784, activation='sigmoid'),\n",
        "                                   Reshape((28,28))])\n",
        "        \n",
        "    def call(self, x):\n",
        "        encoded = self.encoder(x)\n",
        "        decoded = self.decoder(encoded)\n",
        "        return decoded"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xdzD61WI8Yh"
      },
      "source": [
        "### 모델 생성 및 컴파일"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-NtceXVnH7Iu"
      },
      "outputs": [],
      "source": [
        "ae = AutoEncoder(LATENT_DIM)\n",
        "ae.compile(optimizer='adam', loss=MeanSquaredError())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8vKj0ysJAfv"
      },
      "source": [
        "### 모델 학습\n",
        "- x_train 을 입력과 목표 모두로 사용하여 모델을 훈련\n",
        "\n",
        "- encoder 는 데이터 세트를 784 차원에서 잠재 공간으로 압축하는 방법을 배우고,  \n",
        "  decoder 는 원본 이미지를 재구성하는 방법을 배움"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pRqFa-SRz9LN",
        "outputId": "7093374c-3df3-4e6a-a530-d2dfbc61e2b4"
      },
      "outputs": [],
      "source": [
        "ae.fit(X_train, X_train, epochs=30, validation_data=(X_test, X_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GsTLfRXc9Ch3",
        "outputId": "9f36ad13-ca44-45d4-8482-bba6b5dc7dfd"
      },
      "outputs": [],
      "source": [
        "ae.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zA7JfP8FJKlT"
      },
      "source": [
        "### 모델 테스트"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uILZGymOJIBI"
      },
      "outputs": [],
      "source": [
        "encoded_imgs = ae.encoder(X_test).numpy()\n",
        "decoded_imgs = ae.decoder(encoded_imgs).numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "id": "4zu7QR659sZZ",
        "outputId": "271c7b54-731a-40cb-c92d-3f5ffe2860b8"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(16,4))\n",
        "for i in range(10):\n",
        "    plt.subplot(2,10,i+1)\n",
        "    plt.imshow(X_test[i], cmap='gray')\n",
        "    plt.title('Org (28,28)')\n",
        "    plt.axis('off')\n",
        "\n",
        "    plt.subplot(2,10,i+11)\n",
        "    plt.imshow(decoded_imgs[i], cmap='gray')\n",
        "    plt.title('64 -> (28,28)')\n",
        "    plt.axis('off')  \n",
        "plt.show()  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOFigU6FACkb"
      },
      "source": [
        "- Latent dim: 100, Epoch: 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qsLkHCi9-bYp"
      },
      "outputs": [],
      "source": [
        "ae2 = AutoEncoder(100)\n",
        "ae2.compile(optimizer='adam', loss=MeanSquaredError())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFCicwKCB42e",
        "outputId": "df117d2a-7201-457a-c0b4-d522901d1210"
      },
      "outputs": [],
      "source": [
        "ae2.fit(X_train, X_train, epochs=30, validation_data=(X_test, X_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IYhRYLFcB4yh"
      },
      "outputs": [],
      "source": [
        "encoded_imgs2 = ae2.encoder(X_test).numpy()\n",
        "decoded_imgs2 = ae2.decoder(encoded_imgs2).numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_q3VQOnwBlFn"
      },
      "source": [
        "- Latent dim: 40, Epoch: 30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZuNNFH_ABZ-",
        "outputId": "daae4fc6-1fc3-4f13-99dc-7e49e82527af"
      },
      "outputs": [],
      "source": [
        "ae3 = AutoEncoder(40)\n",
        "ae3.compile(optimizer='adam', loss=MeanSquaredError())\n",
        "ae3.fit(X_train, X_train, epochs=30, validation_data=(X_test, X_test), verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j1Ge9vdsC5Lf"
      },
      "outputs": [],
      "source": [
        "encoded_imgs3 = ae3.encoder(X_test).numpy()\n",
        "decoded_imgs3 = ae3.decoder(encoded_imgs3).numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AoQ8YFamBr2G"
      },
      "source": [
        "- Latent dim: 64, Epoch:100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WbV3A2_CABLi",
        "outputId": "7641465f-9437-4f93-ac5f-b34a2ae973ab"
      },
      "outputs": [],
      "source": [
        "ae4 = AutoEncoder(64)\n",
        "ae4.compile(optimizer='adam', loss=MeanSquaredError())\n",
        "ae4.fit(X_train, X_train, epochs=100, validation_data=(X_test, X_test), verbose=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ihm7dNtADreW"
      },
      "outputs": [],
      "source": [
        "encoded_imgs4 = ae4.encoder(X_test).numpy()\n",
        "decoded_imgs4 = ae4.decoder(encoded_imgs4).numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rZjuPFkSEjwn"
      },
      "source": [
        "- 종합 비교"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 572
        },
        "id": "n7Ydh69zElmM",
        "outputId": "53b7de08-51ff-404d-fc7d-33cd0af25b2a"
      },
      "outputs": [],
      "source": [
        "imgs = [X_test, decoded_imgs, decoded_imgs2, decoded_imgs3, decoded_imgs4]\n",
        "titles = ['Original','30, 64nodes','30, 100nodes','30, 40nodes','100, 64nodes']\n",
        "plt.figure(figsize=(16,10))\n",
        "for i, img in enumerate(imgs):\n",
        "    for k in range(10):\n",
        "        plt.subplot(5, 10, i*10 + k + 1)\n",
        "        plt.imshow(img[k], cmap='gray')\n",
        "        plt.title(titles[i]), plt.axis('off')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Osz77MplFsU4"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "21.오토인코더(AE).ipynb",
      "provenance": []
    },
    "interpreter": {
      "hash": "260f019dbdd165b2a66e5fc9588a8f81e21ca9655b1d8c64e54a883dbdaf6a75"
    },
    "kernelspec": {
      "display_name": "Python 3.9.7 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
